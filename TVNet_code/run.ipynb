{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c982bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "from exp.exp_long_term_forecasting import Exp_Long_Term_Forecast\n",
    "#from exp.exp_imputation import Exp_Imputation\n",
    "#from exp.exp_short_term_forecasting import Exp_Short_Term_Forecast\n",
    "#from exp.exp_anomaly_detection import Exp_Anomaly_Detection\n",
    "#from exp.exp_classification import Exp_Classification\n",
    "from utils.print_args import print_args\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63528b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seed\n",
    "fix_seed = 2024\n",
    "random.seed(fix_seed)\n",
    "torch.manual_seed(fix_seed)\n",
    "np.random.seed(fix_seed)\n",
    "parser = argparse.ArgumentParser(description='TVNet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bc6d207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--model'], dest='model', nargs=None, const=None, default='TVNet', type=<class 'str'>, choices=None, required=False, help='model name, options: [Autoformer, Transformer, TimesNet]', metavar=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# basic config\n",
    "parser.add_argument('--task_name', type=str, required=False, default='long_term_forecast',\n",
    "                        help='task name, options:[long_term_forecast, short_term_forecast, imputation, classification, anomaly_detection]')\n",
    "parser.add_argument('--is_training', type=int, required=False, default=1, help='status')\n",
    "parser.add_argument('--model_id', type=str, required=False, default='test', help='model id')\n",
    "parser.add_argument('--model', type=str, required=False, default='TVNet',help='model name, options: [Autoformer, Transformer, TimesNet]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9a68ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--checkpoints'], dest='checkpoints', nargs=None, const=None, default='./checkpoints/', type=<class 'str'>, choices=None, required=False, help='location of model checkpoints', metavar=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data loader\n",
    "parser.add_argument('--data', type=str, required=False, default='ETTh1', help='dataset type')\n",
    "parser.add_argument('--root_path', type=str, default='D:\\LyDeskTop\\IEdownload\\TVNet-main\\TVNet_code\\dataset', help='root path of the data file')\n",
    "parser.add_argument('--data_path', type=str, default='ETTh1.csv', help='data file')\n",
    "parser.add_argument('--features', type=str, default='S',\n",
    "                    help='forecasting task, options:[M, S, MS]; M:multivariate predict multivariate, S:univariate predict univariate, MS:multivariate predict univariate')\n",
    "parser.add_argument('--target', type=str, default='OT', help='target feature in S or MS task')\n",
    "parser.add_argument('--freq', type=str, default='h',\n",
    "                    help='freq for time features encoding, options:[s:secondly, t:minutely, h:hourly, d:daily, b:business days, w:weekly, m:monthly], you can also use more detailed freq like 15min or 3h')\n",
    "parser.add_argument('--checkpoints', type=str, default='./checkpoints/', help='location of model checkpoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7435598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--anomaly_ratio'], dest='anomaly_ratio', nargs=None, const=None, default=0.25, type=<class 'float'>, choices=None, required=False, help='prior anomaly ratio (%)', metavar=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forecasting task\n",
    "parser.add_argument('--seq_len', type=int, default=336, help='input sequence length')\n",
    "parser.add_argument('--label_len', type=int, default=96, help='start token length')\n",
    "parser.add_argument('--pred_len', type=int, default=720, help='prediction sequence length')\n",
    "parser.add_argument('--seasonal_patterns', type=str, default='Monthly', help='subset for M4')\n",
    "parser.add_argument('--inverse', action='store_true', help='inverse output data', default=False)\n",
    "\n",
    "# inputation task\n",
    "parser.add_argument('--mask_rate', type=float, default=0.25, help='mask ratio')\n",
    "\n",
    "# anomaly detection task\n",
    "parser.add_argument('--anomaly_ratio', type=float, default=0.25, help='prior anomaly ratio (%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "916eb2f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--seg_len'], dest='seg_len', nargs=None, const=None, default=48, type=<class 'int'>, choices=None, required=False, help='the length of segmen-wise iteration of SegRNN', metavar=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model define\n",
    "parser.add_argument('--expand', type=int, default=2, help='expansion factor for Mamba')\n",
    "parser.add_argument('--d_conv', type=int, default=4, help='conv kernel size for Mamba')\n",
    "parser.add_argument('--top_k', type=int, default=5, help='for TimesBlock')\n",
    "parser.add_argument('--num_kernels', type=int, default=6, help='for Inception')\n",
    "parser.add_argument('--enc_in', type=int, default=7, help='encoder input size')\n",
    "parser.add_argument('--dec_in', type=int, default=7, help='decoder input size')\n",
    "#parser.add_argument('--d_model', type=int, default=64, help='decoder input size')\n",
    "parser.add_argument('--c_in', type=int, default=1, help='output size')\n",
    "parser.add_argument('--c_out', type=int, default=1, help='output size')\n",
    "parser.add_argument('--d_model', type=int, default=64, help='dimension of model')\n",
    "parser.add_argument('--n_heads', type=int, default=8, help='num of heads')\n",
    "parser.add_argument('--e_layers', type=int, default=2, help='num of encoder layers')\n",
    "parser.add_argument('--d_layers', type=int, default=1, help='num of decoder layers')\n",
    "parser.add_argument('--d_ff', type=int, default=2048, help='dimension of fcn')\n",
    "parser.add_argument('--patch_length', type=int, default=24, help='patch length')\n",
    "parser.add_argument('--stride', type=int, default=12, help='stride')\n",
    "parser.add_argument('--moving_avg', type=int, default=25, help='window size of moving average')\n",
    "parser.add_argument('--factor', type=int, default=1, help='attn factor')\n",
    "parser.add_argument('--distil', action='store_false',\n",
    "                    help='whether to use distilling in encoder, using this argument means not using distilling',\n",
    "                    default=True)\n",
    "parser.add_argument('--layers', type=int, default=3, help='num of layers')\n",
    "parser.add_argument('--dropout', type=float, default=0.1, help='dropout')\n",
    "parser.add_argument('--embed', type=str, default='timeF',\n",
    "                    help='time features encoding, options:[timeF, fixed, learned]')\n",
    "parser.add_argument('--activation', type=str, default='gelu', help='activation')\n",
    "parser.add_argument('--output_attention', action='store_true', help='whether to output attention in ecoder')\n",
    "parser.add_argument('--channel_independence', type=int, default=1,\n",
    "                    help='0: channel dependence 1: channel independence for FreTS model')\n",
    "parser.add_argument('--decomp_method', type=str, default='moving_avg',\n",
    "                    help='method of series decompsition, only support moving_avg or dft_decomp')\n",
    "parser.add_argument('--use_norm', type=int, default=1, help='whether to use normalize; True 1 False 0')\n",
    "parser.add_argument('--down_sampling_layers', type=int, default=0, help='num of down sampling layers')\n",
    "parser.add_argument('--down_sampling_window', type=int, default=1, help='down sampling window size')\n",
    "parser.add_argument('--down_sampling_method', type=str, default=None,\n",
    "                    help='down sampling method, only support avg, max, conv')\n",
    "parser.add_argument('--seg_len', type=int, default=48,\n",
    "                    help='the length of segmen-wise iteration of SegRNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9108da4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--extra_tag'], dest='extra_tag', nargs=None, const=None, default='', type=<class 'str'>, choices=None, required=False, help='Anything extra', metavar=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# optimization\n",
    "parser.add_argument('--num_workers', type=int, default=4, help='data loader num workers')\n",
    "parser.add_argument('--itr', type=int, default=1, help='experiments times')\n",
    "parser.add_argument('--train_epochs', type=int, default=5, help='train epochs')\n",
    "parser.add_argument('--batch_size', type=int, default=32, help='batch size of train input data')\n",
    "parser.add_argument('--patience', type=int, default=3, help='early stopping patience')\n",
    "parser.add_argument('--learning_rate', type=float, default=0.0001, help='optimizer learning rate')\n",
    "parser.add_argument('--des', type=str, default='test', help='exp description')\n",
    "parser.add_argument('--loss', type=str, default='MSE', help='loss function')\n",
    "parser.add_argument('--lradj', type=str, default='type1', help='adjust learning rate')\n",
    "parser.add_argument('--use_amp', action='store_true', help='use automatic mixed precision training', default=False)\n",
    "\n",
    "# GPU\n",
    "parser.add_argument('--use_gpu', type=bool, default=True, help='use gpu')\n",
    "parser.add_argument('--gpu', type=int, default=0, help='gpu')\n",
    "parser.add_argument('--use_multi_gpu', action='store_true', help='use multiple gpus', default=False)\n",
    "parser.add_argument('--devices', type=str, default='0,1,2,3', help='device ids of multile gpus')\n",
    "\n",
    "# de-stationary projector params\n",
    "parser.add_argument('--p_hidden_dims', type=int, nargs='+', default=[128, 128],\n",
    "                    help='hidden layer dimensions of projector (List)')\n",
    "parser.add_argument('--p_hidden_layers', type=int, default=2, help='number of hidden layers in projector')\n",
    "\n",
    "# metrics (dtw)\n",
    "parser.add_argument('--use_dtw', type=bool, default=False, \n",
    "                    help='the controller of using dtw metric (dtw is time consuming, not suggested unless necessary)')\n",
    "\n",
    "# Augmentation\n",
    "parser.add_argument('--augmentation_ratio', type=int, default=0, help=\"How many times to augment\")\n",
    "parser.add_argument('--seed', type=int, default=2, help=\"Randomization seed\")\n",
    "parser.add_argument('--jitter', default=False, action=\"store_true\", help=\"Jitter preset augmentation\")\n",
    "parser.add_argument('--scaling', default=False, action=\"store_true\", help=\"Scaling preset augmentation\")\n",
    "parser.add_argument('--permutation', default=False, action=\"store_true\", help=\"Equal Length Permutation preset augmentation\")\n",
    "parser.add_argument('--randompermutation', default=False, action=\"store_true\", help=\"Random Length Permutation preset augmentation\")\n",
    "parser.add_argument('--magwarp', default=False, action=\"store_true\", help=\"Magnitude warp preset augmentation\")\n",
    "parser.add_argument('--timewarp', default=False, action=\"store_true\", help=\"Time warp preset augmentation\")\n",
    "parser.add_argument('--windowslice', default=False, action=\"store_true\", help=\"Window slice preset augmentation\")\n",
    "parser.add_argument('--windowwarp', default=False, action=\"store_true\", help=\"Window warp preset augmentation\")\n",
    "parser.add_argument('--rotation', default=False, action=\"store_true\", help=\"Rotation preset augmentation\")\n",
    "parser.add_argument('--spawner', default=False, action=\"store_true\", help=\"SPAWNER preset augmentation\")\n",
    "parser.add_argument('--dtwwarp', default=False, action=\"store_true\", help=\"DTW warp preset augmentation\")\n",
    "parser.add_argument('--shapedtwwarp', default=False, action=\"store_true\", help=\"Shape DTW warp preset augmentation\")\n",
    "parser.add_argument('--wdba', default=False, action=\"store_true\", help=\"Weighted DBA preset augmentation\")\n",
    "parser.add_argument('--discdtw', default=False, action=\"store_true\", help=\"Discrimitive DTW warp preset augmentation\")\n",
    "parser.add_argument('--discsdtw', default=False, action=\"store_true\", help=\"Discrimitive shapeDTW warp preset augmentation\")\n",
    "parser.add_argument('--extra_tag', type=str, default=\"\", help=\"Anything extra\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa9e153b",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3362baa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Args in experiment:\n",
      "\u001b[1mBasic Config\u001b[0m\n",
      "  Task Name:          long_term_forecast  Is Training:        1                   \n",
      "  Model ID:           test                Model:              TVNet               \n",
      "\n",
      "\u001b[1mData Loader\u001b[0m\n",
      "  Data:               ETTh1               Root Path:          C:/Users/lenovo/Desktop/research projects/TS video code\\code\\dataset\n",
      "  Data Path:          ETTh1.csv           Features:           S                   \n",
      "  Target:             OT                  Freq:               h                   \n",
      "  Checkpoints:        ./checkpoints/      \n",
      "\n",
      "\u001b[1mForecasting Task\u001b[0m\n",
      "  Seq Len:            336                 Label Len:          96                  \n",
      "  Pred Len:           720                 Seasonal Patterns:  Monthly             \n",
      "  Inverse:            0                   \n",
      "\n",
      "\u001b[1mModel Parameters\u001b[0m\n",
      "  Top k:              5                   Num Kernels:        6                   \n",
      "  Enc In:             7                   Dec In:             7                   \n",
      "  C Out:              1                   d model:            64                  \n",
      "  n heads:            8                   e layers:           2                   \n",
      "  d layers:           1                   d FF:               2048                \n",
      "  Moving Avg:         25                  Factor:             1                   \n",
      "  Distil:             1                   Dropout:            0.1                 \n",
      "  Embed:              timeF               Activation:         gelu                \n",
      "  Output Attention:   0                   \n",
      "\n",
      "\u001b[1mRun Parameters\u001b[0m\n",
      "  Num Workers:        4                   Itr:                1                   \n",
      "  Train Epochs:       5                   Batch Size:         32                  \n",
      "  Patience:           3                   Learning Rate:      0.0001              \n",
      "  Des:                test                Loss:               MSE                 \n",
      "  Lradj:              type1               Use Amp:            0                   \n",
      "\n",
      "\u001b[1mGPU\u001b[0m\n",
      "  Use GPU:            1                   GPU:                0                   \n",
      "  Use Multi GPU:      0                   Devices:            0,1,2,3             \n",
      "\n",
      "\u001b[1mDe-stationary Projector Params\u001b[0m\n",
      "  P Hidden Dims:      128, 128            P Hidden Layers:    2                   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "args.use_gpu = True if torch.cuda.is_available() else False\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "if args.use_gpu and args.use_multi_gpu:\n",
    "    args.devices = args.devices.replace(' ', '')\n",
    "    device_ids = args.devices.split(',')\n",
    "    args.device_ids = [int(id_) for id_ in device_ids]\n",
    "    args.gpu = args.device_ids[0]\n",
    "\n",
    "print('Args in experiment:')\n",
    "print_args(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eab52286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast_test_TVNet_ETTh1_ftS_sl336_ll96_pl720_dm64_nh8_el2_dl1_df2048_expand2_dc4_fc1_ebtimeF_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 7585\n",
      "val 2161\n",
      "test 2161\n",
      "\titers: 100, epoch: 1 | loss: 0.2841305\n",
      "\tspeed: 0.4088s/iter; left time: 443.9117s\n",
      "\titers: 200, epoch: 1 | loss: 0.2184571\n",
      "\tspeed: 0.1030s/iter; left time: 101.5771s\n",
      "Epoch: 1 cost time: 53.362825870513916\n",
      "Epoch: 1, Steps: 237 | Train Loss: 0.2845507 Vali Loss: 0.1581148 Test Loss: 0.2528672\n",
      "Validation loss decreased (inf --> 0.158115).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2486470\n",
      "\tspeed: 1.0633s/iter; left time: 902.7459s\n",
      "\titers: 200, epoch: 2 | loss: 0.1910024\n",
      "\tspeed: 0.1024s/iter; left time: 76.6877s\n",
      "Epoch: 2 cost time: 53.58131647109985\n",
      "Epoch: 2, Steps: 237 | Train Loss: 0.2290124 Vali Loss: 0.1461344 Test Loss: 0.1141454\n",
      "Validation loss decreased (0.158115 --> 0.146134).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2222361\n",
      "\tspeed: 1.0859s/iter; left time: 664.5967s\n",
      "\titers: 200, epoch: 3 | loss: 0.2457263\n",
      "\tspeed: 0.1020s/iter; left time: 52.2184s\n",
      "Epoch: 3 cost time: 53.71863126754761\n",
      "Epoch: 3, Steps: 237 | Train Loss: 0.2193402 Vali Loss: 0.1465157 Test Loss: 0.1561140\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1971038\n",
      "\tspeed: 1.0733s/iter; left time: 402.4729s\n",
      "\titers: 200, epoch: 4 | loss: 0.2338749\n",
      "\tspeed: 0.1013s/iter; left time: 27.8685s\n",
      "Epoch: 4 cost time: 53.75096011161804\n",
      "Epoch: 4, Steps: 237 | Train Loss: 0.2157068 Vali Loss: 0.1476367 Test Loss: 0.1621875\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2104877\n",
      "\tspeed: 1.0622s/iter; left time: 146.5778s\n",
      "\titers: 200, epoch: 5 | loss: 0.1895296\n",
      "\tspeed: 0.1012s/iter; left time: 3.8467s\n",
      "Epoch: 5 cost time: 53.21965503692627\n",
      "Epoch: 5, Steps: 237 | Train Loss: 0.2140137 Vali Loss: 0.1489534 Test Loss: 0.1598461\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast_test_TVNet_ETTh1_ftS_sl336_ll96_pl720_dm64_nh8_el2_dl1_df2048_expand2_dc4_fc1_ebtimeF_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "train 7585\n",
      "test shape: (237, 32, 720, 1) (237, 32, 720, 1)\n",
      "test shape: (7584, 720, 1) (7584, 720, 1)\n",
      "mse:0.22047507762908936, mae:0.3671339750289917, dtw:-999\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if args.task_name == 'long_term_forecast':\n",
    "    Exp = Exp_Long_Term_Forecast\n",
    "elif args.task_name == 'short_term_forecast':\n",
    "    Exp = Exp_Short_Term_Forecast\n",
    "elif args.task_name == 'imputation':\n",
    "    Exp = Exp_Imputation\n",
    "elif args.task_name == 'anomaly_detection':\n",
    "    Exp = Exp_Anomaly_Detection\n",
    "elif args.task_name == 'classification':\n",
    "    Exp = Exp_Classification\n",
    "else:\n",
    "    Exp = Exp_Long_Term_Forecast\n",
    "\n",
    "if args.is_training:\n",
    "    for ii in range(args.itr):\n",
    "        # setting record of experiments\n",
    "        exp = Exp(args)  # set experiments\n",
    "        setting = '{}_{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_expand{}_dc{}_fc{}_eb{}_dt{}_{}_{}'.format(\n",
    "            args.task_name,\n",
    "            args.model_id,\n",
    "            args.model,\n",
    "            args.data,\n",
    "            args.features,\n",
    "            args.seq_len,\n",
    "            args.label_len,\n",
    "            args.pred_len,\n",
    "            args.d_model,\n",
    "            args.n_heads,\n",
    "            args.e_layers,\n",
    "            args.d_layers,\n",
    "            args.d_ff,\n",
    "            args.expand,\n",
    "            args.d_conv,\n",
    "            args.factor,\n",
    "            args.embed,\n",
    "            args.distil,\n",
    "            args.des, ii)\n",
    "\n",
    "        print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n",
    "        exp.train(setting)\n",
    "\n",
    "        print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
    "        exp.test(setting)\n",
    "        torch.cuda.empty_cache()\n",
    "else:\n",
    "    ii = 0\n",
    "    setting = '{}_{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_expand{}_dc{}_fc{}_eb{}_dt{}_{}_{}'.format(\n",
    "        args.task_name,\n",
    "        args.model_id,\n",
    "        args.model,\n",
    "        args.data,\n",
    "        args.features,\n",
    "        args.seq_len,\n",
    "        args.label_len,\n",
    "        args.pred_len,\n",
    "        args.d_model,\n",
    "        args.n_heads,\n",
    "        args.e_layers,\n",
    "        args.d_layers,\n",
    "        args.d_ff,\n",
    "        args.expand,\n",
    "        args.d_conv,\n",
    "        args.factor,\n",
    "        args.embed,\n",
    "        args.distil,\n",
    "        args.des, ii)\n",
    "\n",
    "    exp = Exp(args)  # set experiments\n",
    "    print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
    "    exp.test(setting, test=1)\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8135dd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_cuda",
   "language": "python",
   "name": "torch_cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
